{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from models.resnet20 import resnet20\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "# ------------------------------\n",
    "# CIFAR-10 Loading\n",
    "# ------------------------------\n",
    "def load_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# ------------------------------\n",
    "# L1-Norm Based Filter Pruning\n",
    "# ------------------------------\n",
    "def l1_filter_prune(model, sparsity):\n",
    "    print(f\"[INFO] Applying filter pruning with sparsity {sparsity}\")\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            w = weights[0]  # shape: (h, w, in_channels, out_channels)\n",
    "            b = weights[1] if len(weights) > 1 else None\n",
    "\n",
    "            # Calculate L1 norm of filters\n",
    "            l1_norms = np.sum(np.abs(w), axis=(0, 1, 2))  # per out_channel\n",
    "            num_filters = w.shape[-1]\n",
    "            num_prune = int(num_filters * sparsity)\n",
    "\n",
    "            if num_prune == 0:\n",
    "                continue\n",
    "\n",
    "            prune_idx = np.argsort(l1_norms)[:num_prune]\n",
    "\n",
    "            # Zero out pruned filters\n",
    "            for idx in prune_idx:\n",
    "                w[:, :, :, idx] = 0.0\n",
    "                if b is not None:\n",
    "                    b[idx] = 0.0\n",
    "\n",
    "            if b is not None:\n",
    "                layer.set_weights([w, b])\n",
    "            else:\n",
    "                layer.set_weights([w])\n",
    "\n",
    "# ------------------------------\n",
    "# Training Function\n",
    "# ------------------------------\n",
    "def train(model, x_train, y_train, x_test, y_test, epochs, batch_size, checkpoint_path):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                           monitor='val_accuracy',\n",
    "                                           save_best_only=True,\n",
    "                                           verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks)\n",
    "    return history\n",
    "\n",
    "# ------------------------------\n",
    "# Run Pruning + Training\n",
    "# ------------------------------\n",
    "def run_l1_filter_pruning(sparsity=0.3, epochs=100, batch_size=128):\n",
    "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
    "\n",
    "    model = resnet20()\n",
    "    model.build(input_shape=(None, 32, 32, 3))\n",
    "    model.summary()\n",
    "\n",
    "    l1_filter_prune(model, sparsity)\n",
    "\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    checkpoint_path = f\"results/l1norm_resnet20_sparsity_{sparsity}.h5\"\n",
    "\n",
    "    train(model, x_train, y_train, x_test, y_test, epochs, batch_size, checkpoint_path)\n",
    "    print(\"âœ… Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058231dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_l1_filter_pruning(sparsity=0.4, epochs=150, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
