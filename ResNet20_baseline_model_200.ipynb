{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Import your ResNet-20 model\n",
    "from resnet20_baseline import build_resnet20  # Make sure resnet20_baseline.py is in the same folder or sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5081c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.125,\n",
    "    height_shift_range=0.125,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[100, 150],\n",
    "    values=[0.1, 0.01, 0.001]\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "\n",
    "# Build and compile model\n",
    "model = build_resnet20()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=200,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to specified directory\n",
    "save_path = \"/Users/anshbharti/Documents/SEM-6TH/Research_Paper/cnn_pruning_cifar10/results/baseline_resnet20.h5\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "model.save(save_path)\n",
    "print(f\"Baseline model saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb585344",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ResNet-20 Baseline Training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 80:\n",
    "        return 0.1\n",
    "    elif epoch < 120:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "# Define save path\n",
    "save_path = \"/Users/anshbharti/Documents/SEM-6TH/Research_Paper/cnn_pruning_cifar10/results/baseline_resnet20.h5\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Load CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Normalize\n",
    "mean = x_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std = x_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Build and compile model\n",
    "model = build_resnet20()\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(save_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Training\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=128),\n",
    "          epochs=200,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint, lr_scheduler])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
