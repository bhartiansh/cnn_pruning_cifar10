{"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"478ca5bd","cell_type":"markdown","source":"# Grammar Scoring Engine for Spoken English\nThis project aims to develop a regression model that evaluates grammar usage from spoken audio samples, generating a continuous grammar score between 0 and 5.\n","metadata":{}},{"id":"e78c88b2","cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport joblib\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression\nimport whisper\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom scripts.model import predict_scores\n\n# Load train labels\ntrain_df = pd.read_csv(\"data/audios/train.csv\")\nprint(f\"Number of training samples: {len(train_df)}\")\n\n# Display few samples\ntrain_df.head()\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training samples: 444\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>audio_710.wav</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>audio_1265.wav</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>audio_1114.wav</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>audio_946.wav</td>\n","      <td>1.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>audio_1127.wav</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         filename  label\n","0   audio_710.wav    1.0\n","1  audio_1265.wav    1.0\n","2  audio_1114.wav    1.5\n","3   audio_946.wav    1.5\n","4  audio_1127.wav    2.0"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"execution_count":26},{"id":"b3b7279c","cell_type":"markdown","source":"# Preprocessing Summary\n- All audio files were converted to text using OpenAI's Whisper model.\n- Transcriptions were saved in `transcripts.csv`.\n- Each transcription was analyzed for grammatical errors using LanguageTool.\n- The grammar score is calculated as:\n  > `grammar_score = max(0, 5 - 0.1 * num_errors)`","metadata":{}},{"id":"59072332","cell_type":"code","source":"def transcribe_audio_files(data_dir=\"data/audios/train\", csv_file=\"data/audios/transcripts.csv\"):\n    model = whisper.load_model(\"base\")\n    results = []\n\n    for filename in tqdm(sorted(os.listdir(data_dir))):\n        if filename.endswith(\".wav\"):\n            filepath = os.path.join(data_dir, filename)\n            try:\n                print(f\"Transcribing: {filepath}\")\n                result = model.transcribe(filepath)\n                results.append({\"filename\": filename, \"transcript\": result[\"text\"]})\n            except Exception as e:\n                print(f\"Failed to transcribe {filepath}: {e}\")\n\n    df = pd.DataFrame(results)\n    df.to_csv(csv_file, index=False)\n    print(f\"Transcripts saved to {csv_file}\")\n    \ntranscribe_audio_files(\n    input_dir=\"data/audios/train\",\n    csv_file=\"data/audios/train.csv\",\n    output_csv=\"data/audios/transcripts.csv\"\n)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"14fd0447","cell_type":"markdown","source":"Code for checking the score and saving it","metadata":{}},{"id":"b943eb7d","cell_type":"code","source":"\ndef train_model(transcript_csv_path, train_csv_path):\n    transcripts = pd.read_csv(transcript_csv_path)\n    labels = pd.read_csv(train_csv_path)\n\n    merged = pd.merge(labels, transcripts, on=\"filename\", how=\"inner\")\n    merged = merged.dropna(subset=[\"transcript\", \"label\"])\n\n    X = merged[\"transcript\"]\n    y = merged[\"label\"]\n\n    pipeline = Pipeline([\n        (\"tfidf\", TfidfVectorizer()),\n        (\"lr\", LinearRegression())\n    ])\n    pipeline.fit(X, y)\n\n    os.makedirs(\"model\", exist_ok=True)\n    joblib.dump(pipeline, MODEL_PATH)\n\ndef predict_scores(transcripts):\n    if isinstance(transcripts, pd.Series):\n        transcripts = transcripts.tolist()\n    if not os.path.exists(MODEL_PATH):\n        raise FileNotFoundError(\"Trained model not found.\")\n    pipeline = joblib.load(MODEL_PATH)\n    preds = pipeline.predict(transcripts)\n    return np.clip(preds, 0, 5)\n","metadata":{},"outputs":[],"execution_count":4},{"id":"b50aa22f","cell_type":"code","source":"def run_pipeline(input_csv, test_list, train_csv, output_csv):\n    train_model(input_csv, train_csv)\n\n    all_transcripts = pd.read_csv(input_csv)\n    test_df = pd.read_csv(test_list)\n\n    merged = pd.merge(test_df, all_transcripts, on=\"filename\", how=\"left\")\n    merged[\"transcript\"] = merged[\"transcript\"].fillna(\"\")\n\n    merged[\"label\"] = predict_scores(merged[\"transcript\"])\n    scored_df = merged[[\"filename\", \"label\"]]\n\n    if scored_df.shape[0] != test_df.shape[0]:\n        raise ValueError(f\"Expected {test_df.shape[0]} rows, got {scored_df.shape[0]}.\")\n\n    scored_df.to_csv(output_csv, index=False)\n","metadata":{},"outputs":[],"execution_count":7},{"id":"74a141fe","cell_type":"code","source":"from scripts.pipeline import run_pipeline\n\nrun_pipeline(\n    input_csv=\"data/audios/transcripts.csv\",\n    test_list=\"data/audios/test.csv\",\n    train_csv=\"data/audios/train.csv\",\n    output_csv=\"data/scored_transcripts.csv\"\n)\n","metadata":{},"outputs":[],"execution_count":8},{"id":"07784fd2","cell_type":"code","source":"def score_transcript(text):\n    if not text.strip():\n        return 0.0\n\n    # Example logic (you can replace this with your actual model later)\n    word_count = len(text.split())\n    score = min(5.0, max(0.0, word_count / 20))  # Normalize to 0â€“5\n    return round(score, 2)\n","metadata":{},"outputs":[],"execution_count":9},{"id":"bdc667cf","cell_type":"code","source":"def run_pipeline(input_csv, test_list, output_csv):\n    print(\"Loading transcripts and test file list...\")\n    transcripts = pd.read_csv(input_csv)\n    test_df = pd.read_csv(test_list)\n\n    # Clean up whitespaces and ensure consistent filenames\n    transcripts[\"filename\"] = transcripts[\"filename\"].str.strip()\n    test_df[\"filename\"] = test_df[\"filename\"].str.strip()\n\n    # Merge test list with transcripts\n    merged = test_df.merge(transcripts, on=\"filename\", how=\"left\")\n\n    # Handle missing transcripts\n    missing = merged[\"transcript\"].isnull()\n    if missing.any():\n        for fname in merged.loc[missing, \"filename\"]:\n            print(f\"[!] Missing transcript for {fname}, assigning score 0.0\")\n        merged[\"transcript\"].fillna(\"\", inplace=True)\n\n    # Score the transcripts\n    print(\"[*] Scoring transcripts...\")\n    merged[\"label\"] = merged[\"transcript\"].apply(score_transcript)\n\n    # Output result\n    scored_df = merged[[\"filename\", \"label\"]]\n\n    if scored_df.shape[0] != 195:\n        raise ValueError(f\"[ERROR] Expected 195 rows, got {scored_df.shape[0]}!\")\n\n    scored_df.to_csv(output_csv, index=False)\n    print(f\"Saved {output_csv} with {scored_df.shape[0]} rows.\")\n","metadata":{},"outputs":[],"execution_count":10},{"id":"23440220","cell_type":"code","source":"def run_pipeline(input_csv, test_list, output_csv):\n    # Load all transcripts and test list\n    all_transcripts = pd.read_csv(input_csv)\n    test_files = pd.read_csv(test_list)\n\n    # Drop duplicates in transcripts to avoid inflated merge\n    all_transcripts = all_transcripts.drop_duplicates(subset=\"filename\")\n\n    # Merge test list with available transcripts\n    test_transcripts = pd.merge(\n        test_files, all_transcripts, on=\"filename\", how=\"left\"\n    )\n\n    # Fill missing transcripts with empty string\n    test_transcripts[\"transcript\"] = test_transcripts[\"transcript\"].fillna(\"\")\n\n    # Predict scores\n    scores = predict_scores(test_transcripts[\"transcript\"])\n    test_transcripts[\"label\"] = scores\n\n    # Final scored dataframe with only required columns\n    scored_df = test_transcripts[[\"filename\", \"label\"]]\n\n    # Ensure the number of rows matches test list exactly\n    if scored_df.shape[0] != 195:\n        raise ValueError(f\"Expected 195 rows, got {scored_df.shape[0]}\")\n\n    # Save to CSV\n    scored_df.to_csv(output_csv, index=False)\n\n\n","metadata":{},"outputs":[],"execution_count":12},{"id":"60c83b7c","cell_type":"code","source":"\ndef evaluate_rmse(pred_csv_path, label_csv_path):\n    pred_df = pd.read_csv(pred_csv_path)\n    label_df = pd.read_csv(label_csv_path)\n\n    # Merge on filename to ensure proper alignment\n    merged = pd.merge(label_df, pred_df, on=\"filename\", suffixes=(\"_true\", \"_pred\"))\n\n    # Compute RMSE\n    rmse = mean_squared_error(merged[\"label_true\"], merged[\"label_pred\"], squared=False)\n    return rmse\n","metadata":{},"outputs":[],"execution_count":16},{"id":"89b33ddf","cell_type":"code","source":"# Load train.csv\ntrain_df = pd.read_csv(\"data/audios/train.csv\")\n\n# Load transcripts\ntranscript_df = pd.read_csv(\"data/audios/transcripts.csv\")\n\n# Merge transcript into train_df on filename\nmerged_df = pd.merge(train_df, transcript_df, on=\"filename\", how=\"left\")\n\n# Drop any rows with missing transcripts\nmerged_df = merged_df.dropna(subset=[\"transcript\"])\n\n# Predict scores\nmerged_df[\"predicted\"] = predict_scores(merged_df[\"transcript\"])\n\n# Save predictions\nmerged_df[[\"filename\", \"predicted\"]].to_csv(\"data/train_predictions.csv\", index=False)\n\n","metadata":{},"outputs":[],"execution_count":27},{"id":"98a9adbc","cell_type":"code","source":"true = pd.read_csv(\"data/audios/train.csv\")\npred = pd.read_csv(\"data/train_predictions.csv\")\n\nmerged = pd.merge(true, pred, on=\"filename\")\nrmse = mean_squared_error(merged[\"label\"], merged[\"predicted\"], squared=False)\nprint(\"RMSE:\", rmse)\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 0.2099146758382819\n"]},{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n","  warnings.warn(\n"]}],"execution_count":28},{"id":"75c01d95","cell_type":"markdown","source":"","metadata":{}},{"id":"3e934aea","cell_type":"markdown","source":"# Conclusion\n- Whisper-based transcription enabled high-quality text generation from spoken audio.\n- Grammar scores derived using rule-based error detection.\n- A linear regression model was used to map errors to MOS grammar scores.\n- RMSE on training set: `0.2099146758382819`\n","metadata":{}}]}