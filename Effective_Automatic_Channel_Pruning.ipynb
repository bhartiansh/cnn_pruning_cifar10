{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhartiansh/cnn_pruning_cifar10/blob/main/Effective_Automatic_Channel_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnFKRMPZ_f3n",
        "outputId": "da08cc3d-acdf-4e5b-9cf6-dab287c16a3e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('../models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2eg7IPLJ_lwb"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K4ZZbexM_qbf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from models.resnet20 import build_resnet20  # Your custom ResNet-20 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gPGT1B6M_rki"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Step 1: Cluster filters using cosine similarity\n",
        "# -------------------------------\n",
        "def cluster_filters(layer_weights, num_clusters):\n",
        "    filters = layer_weights.reshape(layer_weights.shape[-1], -1)\n",
        "    filters_norm = np.linalg.norm(filters, axis=1, keepdims=True)\n",
        "    filters_normalized = filters / (filters_norm + 1e-8)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init='auto')\n",
        "    kmeans.fit(filters_normalized)  # ✅ Fit first!\n",
        "    return kmeans.labels_           # ✅ Then get labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "in_-Guo3_tMq"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Step 2: Apply pruning by retaining one filter per cluster\n",
        "# -------------------------------\n",
        "def prune_filters(layer, cluster_labels):\n",
        "    weights, biases = layer.get_weights()\n",
        "    num_filters = weights.shape[-1]\n",
        "    keep_mask = np.zeros(num_filters, dtype=bool)\n",
        "\n",
        "    for cluster_id in np.unique(cluster_labels):\n",
        "        indices = np.where(cluster_labels == cluster_id)[0]\n",
        "        keep_mask[indices[0]] = True  # Keep one representative\n",
        "\n",
        "    weights[..., ~keep_mask] = 0\n",
        "    if biases is not None:\n",
        "        biases[~keep_mask] = 0\n",
        "\n",
        "    layer.set_weights([weights, biases])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LajInQXu_x0S"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# Step 3: EACP pruning and training pipeline (no pre-training)\n",
        "# -------------------------------\n",
        "def train_eacp_model(x_train, y_train, x_val, y_val,\n",
        "                     sparsity=0.5, epochs=50, batch_size=128):\n",
        "    model = build_resnet20()\n",
        "\n",
        "    print(f\"Applying EACP pruning with sparsity = {sparsity:.2f}...\")\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            weights = layer.get_weights()[0]\n",
        "            num_filters = weights.shape[-1]\n",
        "            num_clusters = max(1, int(num_filters * (1 - sparsity)))\n",
        "\n",
        "            if num_clusters < num_filters:\n",
        "                cluster_labels = cluster_filters(weights, num_clusters)\n",
        "                prune_filters(layer, cluster_labels)\n",
        "\n",
        "    print(\"Fine-tuning pruned model...\")\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_val, y_val),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)],\n",
        "              verbose=2)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYrqME2j_vQc",
        "outputId": "e1feb9e7-3ff6-481e-bede-316d98956d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying EACP pruning with sparsity = 0.30...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning pruned model...\n",
            "Epoch 1/30\n",
            "782/782 - 50s - loss: 1.3551 - accuracy: 0.5105 - val_loss: 1.7057 - val_accuracy: 0.4802 - 50s/epoch - 64ms/step\n",
            "Epoch 2/30\n",
            "782/782 - 33s - loss: 0.9461 - accuracy: 0.6636 - val_loss: 1.0769 - val_accuracy: 0.6281 - 33s/epoch - 42ms/step\n",
            "Epoch 3/30\n",
            "782/782 - 33s - loss: 0.7704 - accuracy: 0.7328 - val_loss: 0.8460 - val_accuracy: 0.7119 - 33s/epoch - 43ms/step\n",
            "Epoch 4/30\n",
            "782/782 - 34s - loss: 0.6664 - accuracy: 0.7694 - val_loss: 0.9632 - val_accuracy: 0.6820 - 34s/epoch - 43ms/step\n",
            "Epoch 5/30\n",
            "782/782 - 33s - loss: 0.5922 - accuracy: 0.7933 - val_loss: 1.1416 - val_accuracy: 0.6543 - 33s/epoch - 42ms/step\n",
            "Epoch 6/30\n",
            "782/782 - 33s - loss: 0.5338 - accuracy: 0.8163 - val_loss: 1.0394 - val_accuracy: 0.6757 - 33s/epoch - 42ms/step\n",
            "Epoch 7/30\n",
            "782/782 - 33s - loss: 0.4838 - accuracy: 0.8322 - val_loss: 0.7286 - val_accuracy: 0.7562 - 33s/epoch - 42ms/step\n",
            "Epoch 8/30\n",
            "782/782 - 36s - loss: 0.4414 - accuracy: 0.8459 - val_loss: 0.8016 - val_accuracy: 0.7419 - 36s/epoch - 45ms/step\n",
            "Epoch 9/30\n",
            "782/782 - 95s - loss: 0.3963 - accuracy: 0.8614 - val_loss: 0.7849 - val_accuracy: 0.7564 - 95s/epoch - 122ms/step\n",
            "Epoch 10/30\n",
            "782/782 - 58s - loss: 0.3590 - accuracy: 0.8737 - val_loss: 0.8726 - val_accuracy: 0.7330 - 58s/epoch - 74ms/step\n",
            "Epoch 11/30\n",
            "782/782 - 33s - loss: 0.3306 - accuracy: 0.8843 - val_loss: 0.9348 - val_accuracy: 0.7308 - 33s/epoch - 43ms/step\n",
            "Epoch 12/30\n",
            "782/782 - 34s - loss: 0.2960 - accuracy: 0.8973 - val_loss: 0.6950 - val_accuracy: 0.7836 - 34s/epoch - 43ms/step\n",
            "Epoch 13/30\n",
            "782/782 - 34s - loss: 0.2755 - accuracy: 0.9041 - val_loss: 0.8407 - val_accuracy: 0.7605 - 34s/epoch - 43ms/step\n",
            "Epoch 14/30\n",
            "782/782 - 33s - loss: 0.2457 - accuracy: 0.9134 - val_loss: 0.9822 - val_accuracy: 0.7406 - 33s/epoch - 42ms/step\n",
            "Epoch 15/30\n",
            "782/782 - 33s - loss: 0.2205 - accuracy: 0.9230 - val_loss: 0.8558 - val_accuracy: 0.7682 - 33s/epoch - 42ms/step\n",
            "Epoch 16/30\n",
            "782/782 - 33s - loss: 0.2014 - accuracy: 0.9279 - val_loss: 0.7859 - val_accuracy: 0.7860 - 33s/epoch - 42ms/step\n",
            "Epoch 17/30\n",
            "782/782 - 33s - loss: 0.1842 - accuracy: 0.9353 - val_loss: 0.9069 - val_accuracy: 0.7602 - 33s/epoch - 42ms/step\n",
            "Epoch 18/30\n",
            "782/782 - 33s - loss: 0.1745 - accuracy: 0.9377 - val_loss: 1.0065 - val_accuracy: 0.7612 - 33s/epoch - 42ms/step\n",
            "Epoch 19/30\n",
            "782/782 - 33s - loss: 0.1586 - accuracy: 0.9431 - val_loss: 0.7649 - val_accuracy: 0.7910 - 33s/epoch - 42ms/step\n",
            "Epoch 20/30\n",
            "782/782 - 33s - loss: 0.1405 - accuracy: 0.9504 - val_loss: 0.9809 - val_accuracy: 0.7663 - 33s/epoch - 42ms/step\n",
            "Epoch 21/30\n",
            "782/782 - 33s - loss: 0.1295 - accuracy: 0.9545 - val_loss: 0.8685 - val_accuracy: 0.7796 - 33s/epoch - 42ms/step\n",
            "Epoch 22/30\n",
            "782/782 - 33s - loss: 0.1338 - accuracy: 0.9519 - val_loss: 1.0862 - val_accuracy: 0.7432 - 33s/epoch - 42ms/step\n",
            "Epoch 23/30\n",
            "782/782 - 33s - loss: 0.1133 - accuracy: 0.9586 - val_loss: 0.9585 - val_accuracy: 0.7850 - 33s/epoch - 42ms/step\n",
            "Epoch 24/30\n",
            "782/782 - 33s - loss: 0.1074 - accuracy: 0.9624 - val_loss: 0.9066 - val_accuracy: 0.7856 - 33s/epoch - 42ms/step\n",
            "Epoch 25/30\n",
            "782/782 - 33s - loss: 0.1137 - accuracy: 0.9586 - val_loss: 0.9302 - val_accuracy: 0.7902 - 33s/epoch - 42ms/step\n",
            "Epoch 26/30\n",
            "782/782 - 33s - loss: 0.1026 - accuracy: 0.9638 - val_loss: 1.1156 - val_accuracy: 0.7641 - 33s/epoch - 42ms/step\n",
            "Epoch 27/30\n",
            "782/782 - 33s - loss: 0.0928 - accuracy: 0.9663 - val_loss: 1.0391 - val_accuracy: 0.7897 - 33s/epoch - 42ms/step\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 (unchanged)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Train with EACP (ResNet-20)\n",
        "model = train_eacp_model(x_train, y_train, x_test, y_test, sparsity=0.3, epochs=30, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YGXwBeAVAsUB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying EACP pruning with sparsity = 0.50...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning pruned model...\n",
            "Epoch 1/30\n",
            "782/782 - 38s - loss: 1.4288 - accuracy: 0.4759 - val_loss: 1.8455 - val_accuracy: 0.4112 - 38s/epoch - 49ms/step\n",
            "Epoch 2/30\n",
            "782/782 - 33s - loss: 1.0196 - accuracy: 0.6382 - val_loss: 1.4083 - val_accuracy: 0.5257 - 33s/epoch - 42ms/step\n",
            "Epoch 3/30\n",
            "782/782 - 33s - loss: 0.8501 - accuracy: 0.7002 - val_loss: 1.3553 - val_accuracy: 0.5501 - 33s/epoch - 42ms/step\n",
            "Epoch 4/30\n",
            "782/782 - 33s - loss: 0.7397 - accuracy: 0.7412 - val_loss: 1.1875 - val_accuracy: 0.6136 - 33s/epoch - 43ms/step\n",
            "Epoch 5/30\n",
            "782/782 - 33s - loss: 0.6643 - accuracy: 0.7657 - val_loss: 0.8108 - val_accuracy: 0.7243 - 33s/epoch - 42ms/step\n",
            "Epoch 6/30\n",
            "782/782 - 33s - loss: 0.6082 - accuracy: 0.7890 - val_loss: 0.8519 - val_accuracy: 0.7150 - 33s/epoch - 42ms/step\n",
            "Epoch 7/30\n",
            "782/782 - 33s - loss: 0.5575 - accuracy: 0.8051 - val_loss: 1.1154 - val_accuracy: 0.6568 - 33s/epoch - 43ms/step\n",
            "Epoch 8/30\n",
            "782/782 - 33s - loss: 0.5229 - accuracy: 0.8183 - val_loss: 0.8079 - val_accuracy: 0.7295 - 33s/epoch - 42ms/step\n",
            "Epoch 9/30\n",
            "782/782 - 33s - loss: 0.4842 - accuracy: 0.8297 - val_loss: 0.9856 - val_accuracy: 0.6896 - 33s/epoch - 42ms/step\n",
            "Epoch 10/30\n",
            "782/782 - 33s - loss: 0.4543 - accuracy: 0.8416 - val_loss: 1.1831 - val_accuracy: 0.6624 - 33s/epoch - 42ms/step\n",
            "Epoch 11/30\n",
            "782/782 - 33s - loss: 0.4211 - accuracy: 0.8516 - val_loss: 0.7423 - val_accuracy: 0.7564 - 33s/epoch - 43ms/step\n",
            "Epoch 12/30\n",
            "782/782 - 33s - loss: 0.3929 - accuracy: 0.8639 - val_loss: 0.7858 - val_accuracy: 0.7495 - 33s/epoch - 42ms/step\n",
            "Epoch 13/30\n",
            "782/782 - 33s - loss: 0.3771 - accuracy: 0.8684 - val_loss: 0.9230 - val_accuracy: 0.7340 - 33s/epoch - 42ms/step\n",
            "Epoch 14/30\n",
            "782/782 - 33s - loss: 0.3477 - accuracy: 0.8779 - val_loss: 0.7257 - val_accuracy: 0.7676 - 33s/epoch - 42ms/step\n",
            "Epoch 15/30\n",
            "782/782 - 33s - loss: 0.3266 - accuracy: 0.8852 - val_loss: 0.7468 - val_accuracy: 0.7798 - 33s/epoch - 42ms/step\n",
            "Epoch 16/30\n",
            "782/782 - 33s - loss: 0.3037 - accuracy: 0.8928 - val_loss: 0.8052 - val_accuracy: 0.7614 - 33s/epoch - 42ms/step\n",
            "Epoch 17/30\n",
            "782/782 - 33s - loss: 0.2856 - accuracy: 0.8979 - val_loss: 0.9806 - val_accuracy: 0.7175 - 33s/epoch - 42ms/step\n",
            "Epoch 18/30\n",
            "782/782 - 35s - loss: 0.2725 - accuracy: 0.9034 - val_loss: 0.8612 - val_accuracy: 0.7574 - 35s/epoch - 45ms/step\n",
            "Epoch 19/30\n",
            "782/782 - 34s - loss: 0.2507 - accuracy: 0.9112 - val_loss: 0.8334 - val_accuracy: 0.7616 - 34s/epoch - 43ms/step\n",
            "Epoch 20/30\n",
            "782/782 - 33s - loss: 0.2385 - accuracy: 0.9162 - val_loss: 0.7894 - val_accuracy: 0.7740 - 33s/epoch - 42ms/step\n",
            "Epoch 21/30\n",
            "782/782 - 33s - loss: 0.2192 - accuracy: 0.9215 - val_loss: 0.9483 - val_accuracy: 0.7494 - 33s/epoch - 43ms/step\n",
            "Epoch 22/30\n",
            "782/782 - 34s - loss: 0.2090 - accuracy: 0.9265 - val_loss: 0.9033 - val_accuracy: 0.7661 - 34s/epoch - 43ms/step\n",
            "Epoch 23/30\n",
            "782/782 - 33s - loss: 0.1944 - accuracy: 0.9312 - val_loss: 1.0850 - val_accuracy: 0.7353 - 33s/epoch - 42ms/step\n",
            "Epoch 24/30\n",
            "782/782 - 33s - loss: 0.1842 - accuracy: 0.9346 - val_loss: 0.8553 - val_accuracy: 0.7733 - 33s/epoch - 42ms/step\n",
            "Epoch 25/30\n",
            "782/782 - 33s - loss: 0.1764 - accuracy: 0.9370 - val_loss: 1.0282 - val_accuracy: 0.7477 - 33s/epoch - 42ms/step\n",
            "Epoch 26/30\n",
            "782/782 - 33s - loss: 0.1632 - accuracy: 0.9424 - val_loss: 0.9044 - val_accuracy: 0.7702 - 33s/epoch - 43ms/step\n",
            "Epoch 27/30\n",
            "782/782 - 33s - loss: 0.1556 - accuracy: 0.9441 - val_loss: 1.2289 - val_accuracy: 0.7288 - 33s/epoch - 42ms/step\n",
            "Epoch 28/30\n",
            "782/782 - 33s - loss: 0.1448 - accuracy: 0.9489 - val_loss: 1.0924 - val_accuracy: 0.7437 - 33s/epoch - 43ms/step\n",
            "Epoch 29/30\n",
            "782/782 - 35s - loss: 0.1420 - accuracy: 0.9491 - val_loss: 1.0546 - val_accuracy: 0.7558 - 35s/epoch - 45ms/step\n",
            "Epoch 30/30\n",
            "782/782 - 32s - loss: 0.1364 - accuracy: 0.9503 - val_loss: 1.0102 - val_accuracy: 0.7613 - 32s/epoch - 41ms/step\n"
          ]
        }
      ],
      "source": [
        "0# Load CIFAR-10 (unchanged)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Train with EACP (ResNet-20)\n",
        "model = train_eacp_model(x_train, y_train, x_test, y_test, sparsity=0.5, epochs=30, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RTZJHG6DAt7r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying EACP pruning with sparsity = 0.70...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\kabir\\tf-gpu-env\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning pruned model...\n",
            "Epoch 1/30\n",
            "782/782 - 33s - loss: 1.4924 - accuracy: 0.4537 - val_loss: 2.5461 - val_accuracy: 0.3102 - 33s/epoch - 43ms/step\n",
            "Epoch 2/30\n",
            "782/782 - 32s - loss: 1.1127 - accuracy: 0.6045 - val_loss: 1.2702 - val_accuracy: 0.5577 - 32s/epoch - 41ms/step\n",
            "Epoch 3/30\n",
            "782/782 - 30s - loss: 0.9664 - accuracy: 0.6592 - val_loss: 2.6670 - val_accuracy: 0.3517 - 30s/epoch - 39ms/step\n",
            "Epoch 4/30\n",
            "782/782 - 30s - loss: 0.8800 - accuracy: 0.6896 - val_loss: 1.0959 - val_accuracy: 0.6229 - 30s/epoch - 38ms/step\n",
            "Epoch 5/30\n",
            "782/782 - 30s - loss: 0.8142 - accuracy: 0.7139 - val_loss: 0.9568 - val_accuracy: 0.6703 - 30s/epoch - 38ms/step\n",
            "Epoch 6/30\n",
            "782/782 - 30s - loss: 0.7609 - accuracy: 0.7329 - val_loss: 1.0128 - val_accuracy: 0.6449 - 30s/epoch - 38ms/step\n",
            "Epoch 7/30\n",
            "782/782 - 30s - loss: 0.7168 - accuracy: 0.7490 - val_loss: 0.9138 - val_accuracy: 0.6811 - 30s/epoch - 39ms/step\n",
            "Epoch 8/30\n",
            "782/782 - 30s - loss: 0.6769 - accuracy: 0.7631 - val_loss: 1.0939 - val_accuracy: 0.6417 - 30s/epoch - 38ms/step\n",
            "Epoch 9/30\n",
            "782/782 - 30s - loss: 0.6464 - accuracy: 0.7740 - val_loss: 1.1863 - val_accuracy: 0.6200 - 30s/epoch - 38ms/step\n",
            "Epoch 10/30\n",
            "782/782 - 31s - loss: 0.6211 - accuracy: 0.7824 - val_loss: 0.9768 - val_accuracy: 0.6687 - 31s/epoch - 39ms/step\n",
            "Epoch 11/30\n",
            "782/782 - 30s - loss: 0.5971 - accuracy: 0.7921 - val_loss: 0.9512 - val_accuracy: 0.6836 - 30s/epoch - 38ms/step\n",
            "Epoch 12/30\n",
            "782/782 - 30s - loss: 0.5744 - accuracy: 0.7994 - val_loss: 1.0635 - val_accuracy: 0.6709 - 30s/epoch - 38ms/step\n",
            "Epoch 13/30\n",
            "782/782 - 30s - loss: 0.5527 - accuracy: 0.8073 - val_loss: 0.9301 - val_accuracy: 0.7000 - 30s/epoch - 38ms/step\n",
            "Epoch 14/30\n",
            "782/782 - 30s - loss: 0.5361 - accuracy: 0.8122 - val_loss: 1.0074 - val_accuracy: 0.6847 - 30s/epoch - 38ms/step\n",
            "Epoch 15/30\n",
            "782/782 - 30s - loss: 0.5177 - accuracy: 0.8195 - val_loss: 0.8317 - val_accuracy: 0.7384 - 30s/epoch - 38ms/step\n",
            "Epoch 16/30\n",
            "782/782 - 30s - loss: 0.5000 - accuracy: 0.8248 - val_loss: 1.0008 - val_accuracy: 0.6975 - 30s/epoch - 38ms/step\n",
            "Epoch 17/30\n",
            "782/782 - 30s - loss: 0.4885 - accuracy: 0.8295 - val_loss: 0.9158 - val_accuracy: 0.6909 - 30s/epoch - 38ms/step\n",
            "Epoch 18/30\n",
            "782/782 - 30s - loss: 0.4770 - accuracy: 0.8332 - val_loss: 1.0266 - val_accuracy: 0.6871 - 30s/epoch - 38ms/step\n",
            "Epoch 19/30\n",
            "782/782 - 30s - loss: 0.4602 - accuracy: 0.8381 - val_loss: 1.0005 - val_accuracy: 0.6919 - 30s/epoch - 38ms/step\n",
            "Epoch 20/30\n",
            "782/782 - 30s - loss: 0.4494 - accuracy: 0.8422 - val_loss: 0.9029 - val_accuracy: 0.7150 - 30s/epoch - 38ms/step\n",
            "Epoch 21/30\n",
            "782/782 - 30s - loss: 0.4362 - accuracy: 0.8474 - val_loss: 0.8363 - val_accuracy: 0.7288 - 30s/epoch - 38ms/step\n",
            "Epoch 22/30\n",
            "782/782 - 30s - loss: 0.4263 - accuracy: 0.8505 - val_loss: 0.8200 - val_accuracy: 0.7373 - 30s/epoch - 38ms/step\n",
            "Epoch 23/30\n",
            "782/782 - 30s - loss: 0.4158 - accuracy: 0.8537 - val_loss: 0.8899 - val_accuracy: 0.7152 - 30s/epoch - 38ms/step\n",
            "Epoch 24/30\n",
            "782/782 - 30s - loss: 0.3990 - accuracy: 0.8606 - val_loss: 0.9004 - val_accuracy: 0.7214 - 30s/epoch - 38ms/step\n",
            "Epoch 25/30\n",
            "782/782 - 30s - loss: 0.3951 - accuracy: 0.8602 - val_loss: 0.8663 - val_accuracy: 0.7235 - 30s/epoch - 38ms/step\n",
            "Epoch 26/30\n",
            "782/782 - 30s - loss: 0.3855 - accuracy: 0.8627 - val_loss: 0.9471 - val_accuracy: 0.7170 - 30s/epoch - 38ms/step\n",
            "Epoch 27/30\n",
            "782/782 - 67s - loss: 0.3757 - accuracy: 0.8687 - val_loss: 0.7895 - val_accuracy: 0.7506 - 67s/epoch - 85ms/step\n",
            "Epoch 28/30\n",
            "782/782 - 29s - loss: 0.3650 - accuracy: 0.8715 - val_loss: 0.8636 - val_accuracy: 0.7391 - 29s/epoch - 37ms/step\n",
            "Epoch 29/30\n",
            "782/782 - 29s - loss: 0.3594 - accuracy: 0.8718 - val_loss: 0.9953 - val_accuracy: 0.7088 - 29s/epoch - 37ms/step\n",
            "Epoch 30/30\n",
            "782/782 - 29s - loss: 0.3488 - accuracy: 0.8761 - val_loss: 1.4475 - val_accuracy: 0.6321 - 29s/epoch - 37ms/step\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 (unchanged)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Train with EACP (ResNet-20)\n",
        "model = train_eacp_model(x_train, y_train, x_test, y_test, sparsity=0.7, epochs=30, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0pSd4ts_xTb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVC65e6x_xQ4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCnOKXIH_xOI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w_nLKdw_xLW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9bnnNac_xIk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqXKJ6AE_xFy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwOEUdgj_xDA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hcvVmMC_xAV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi5WOFFs_w9j"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiFn05W9_w6h"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NESXqR-g_esX",
        "outputId": "4080576d-095d-455c-94f2-8c9696101c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e1e9b8fbea714e33a2d54b5f2aa2a2ec",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.14.0)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.14.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow==2.14.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.14.0)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.14.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow==2.14.0)\n",
            "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.14.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy>=1.23.5 (from tensorflow==2.14.0)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow==2.14.0)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.14.0)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.14.0)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow==2.14.0)\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow==2.14.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.14.0)\n",
            "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.14.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.14.0)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.14.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "tensorflow-model-optimization 0.8.0 requires absl-py~=1.2, but you have absl-py 2.2.2 which is incompatible.\n",
            "tensorflow-model-optimization 0.8.0 requires numpy~=1.23, but you have numpy 2.2.4 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-auth-2.39.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-2.14.0 libclang-18.1.1 markdown-3.8 ml-dtypes-0.2.0 numpy-2.2.4 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-24.2 protobuf-4.25.6 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-78.1.0 six-1.17.0 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "9b160633d42e48078ba1b499e4d26aeb",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "absl",
                  "astunparse",
                  "cachetools",
                  "certifi",
                  "charset_normalizer",
                  "flatbuffers",
                  "gast",
                  "google",
                  "h5py",
                  "ml_dtypes",
                  "pyasn1",
                  "pyasn1_modules",
                  "requests",
                  "setuptools",
                  "six",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Collecting absl-py~=1.2 (from tensorflow-model-optimization)\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Collecting numpy~=1.23 (from tensorflow-model-optimization)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.14.1)\n",
            "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy, absl-py\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-1.4.0 numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "# 1. Force compatible versions (reset everything to Colab defaults)\n",
        "!pip install -U --force-reinstall numpy==1.23.5\n",
        "!pip install -U --force-reinstall tensorflow==2.14.0\n",
        "!pip install -U tensorflow-model-optimization\n",
        "\n",
        "# 2. Restart runtime automatically after install\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMxdqbGdhASO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMdwYzAozJDJFHPcs7qBsKM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
