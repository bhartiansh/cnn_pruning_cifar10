{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZneFspZkIdC/V7iOnl6MJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhartiansh/cnn_pruning_cifar10/blob/main/pruning4(One_cycle_Structured_Pruning_with_Stability_Driven_Structure_Search).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bhartiansh/cnn_pruning_cifar10.git\n",
        "%cd cnn_pruning_cifar10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk2Bju1qWWss",
        "outputId": "b9aeac6d-966b-42ee-a236-54ad7df7e343"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cnn_pruning_cifar10'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 114 (delta 47), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (114/114), 85.20 KiB | 660.00 KiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "/content/cnn_pruning_cifar10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2t-T5a9lpyx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf6KQpNNpr2Q",
        "outputId": "33c59d2e-cacc-4bd8-9bca-a22a6c98dc51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t\t\t     'pruning4(L1_Norm_Filter).ipynb'\n",
            " lth_pruning_20_40_60.ipynb  'pruning5(Random_Pruning_Unstructured).ipynb'\n",
            " models\t\t\t      README.md\n",
            "'pruning1(lth).ipynb'\t      ResNet56_baseline_model.ipynb\n",
            "'pruning2(SNIP).ipynb'\t      traning\n",
            "'pruning3(MAG_50).ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "e_Up2OD-XhzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "addc0523-8741-41d6-a524-c5c6e809c966"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from models.resnet56_baseline import build_resnet56\n",
        "\n",
        "def get_conv_layers(model):\n",
        "    return [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "\n",
        "def compute_group_saliency(model):\n",
        "    saliency = {}\n",
        "    for layer in get_conv_layers(model):\n",
        "        weights = layer.get_weights()[0]  # shape: (k, k, in_channels, out_channels)\n",
        "        l2_norms = np.linalg.norm(weights.reshape(-1, weights.shape[-1]), axis=0)\n",
        "        saliency[layer.name] = l2_norms\n",
        "    return saliency\n",
        "\n",
        "def prune_filters(model, saliency, pruning_ratio):\n",
        "    for layer in get_conv_layers(model):\n",
        "        weights, bias = layer.get_weights()\n",
        "        l2_norms = saliency[layer.name]\n",
        "        num_filters = weights.shape[-1]\n",
        "        num_prune = int(pruning_ratio * num_filters)\n",
        "        prune_indices = np.argsort(l2_norms)[:num_prune]\n",
        "        weights[..., prune_indices] = 0\n",
        "        if bias is not None:\n",
        "            bias[prune_indices] = 0\n",
        "        layer.set_weights([weights, bias])\n",
        "\n",
        "def train_one_cycle_pruned_model(x_train, y_train, x_val, y_val,\n",
        "                                 pruning_ratio=0.3, epochs=50, batch_size=128):\n",
        "    model = build_resnet56()\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    # Initial training to compute saliency\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_acc_metric])\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=batch_size, validation_data=(x_val, y_val))\n",
        "\n",
        "    # Compute saliency and prune\n",
        "    saliency = compute_group_saliency(model)\n",
        "    prune_filters(model, saliency, pruning_ratio)\n",
        "\n",
        "    # Fine-tune pruned model\n",
        "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=[train_acc_metric])\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3XT_FKNcupSE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Train pruned model\n",
        "model = train_one_cycle_pruned_model(x_train, y_train, x_test, y_test, pruning_ratio=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agaXS7FfwhJj",
        "outputId": "5cd24236-5362-4ba4-a1da-c91e6878db6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 120ms/step - loss: 2.0687 - sparse_categorical_accuracy: 0.3562 - val_loss: 1.4917 - val_sparse_categorical_accuracy: 0.4618\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - loss: 1.1231 - sparse_categorical_accuracy: 0.5958 - val_loss: 1.4507 - val_sparse_categorical_accuracy: 0.5460\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 72ms/step - loss: 0.8655 - sparse_categorical_accuracy: 0.6929 - val_loss: 0.9674 - val_sparse_categorical_accuracy: 0.6581\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 72ms/step - loss: 0.6988 - sparse_categorical_accuracy: 0.7505 - val_loss: 1.1170 - val_sparse_categorical_accuracy: 0.6447\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 76ms/step - loss: 0.5877 - sparse_categorical_accuracy: 0.7914 - val_loss: 0.8135 - val_sparse_categorical_accuracy: 0.7222\n",
            "Epoch 1/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 120ms/step - loss: 1.4360 - sparse_categorical_accuracy: 0.6103 - val_loss: 1.2702 - val_sparse_categorical_accuracy: 0.5969\n",
            "Epoch 2/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 74ms/step - loss: 0.6639 - sparse_categorical_accuracy: 0.7651 - val_loss: 0.8197 - val_sparse_categorical_accuracy: 0.7259\n",
            "Epoch 3/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 77ms/step - loss: 0.5404 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.9309 - val_sparse_categorical_accuracy: 0.7003\n",
            "Epoch 4/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 78ms/step - loss: 0.4435 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.9637 - val_sparse_categorical_accuracy: 0.6968\n",
            "Epoch 5/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 79ms/step - loss: 0.3774 - sparse_categorical_accuracy: 0.8677 - val_loss: 0.8559 - val_sparse_categorical_accuracy: 0.7271\n",
            "Epoch 6/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.8340 - val_sparse_categorical_accuracy: 0.7466\n",
            "Epoch 7/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.9055 - val_loss: 0.8048 - val_sparse_categorical_accuracy: 0.7541\n",
            "Epoch 8/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - loss: 0.2287 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.9525 - val_sparse_categorical_accuracy: 0.7336\n",
            "Epoch 9/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 74ms/step - loss: 0.1902 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.9657 - val_sparse_categorical_accuracy: 0.7447\n",
            "Epoch 10/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9464 - val_loss: 1.0580 - val_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 11/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - loss: 0.1347 - sparse_categorical_accuracy: 0.9529 - val_loss: 1.2075 - val_sparse_categorical_accuracy: 0.7335\n",
            "Epoch 12/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9585 - val_loss: 0.8849 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 13/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - loss: 0.1042 - sparse_categorical_accuracy: 0.9655 - val_loss: 1.0076 - val_sparse_categorical_accuracy: 0.7607\n",
            "Epoch 14/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 78ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9683 - val_loss: 1.1820 - val_sparse_categorical_accuracy: 0.7482\n",
            "Epoch 15/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9687 - val_loss: 1.2549 - val_sparse_categorical_accuracy: 0.7434\n",
            "Epoch 16/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - loss: 0.0747 - sparse_categorical_accuracy: 0.9743 - val_loss: 1.3567 - val_sparse_categorical_accuracy: 0.7389\n",
            "Epoch 17/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9770 - val_loss: 1.3200 - val_sparse_categorical_accuracy: 0.7344\n",
            "Epoch 18/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 75ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9770 - val_loss: 1.1253 - val_sparse_categorical_accuracy: 0.7734\n",
            "Epoch 19/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9780 - val_loss: 1.2559 - val_sparse_categorical_accuracy: 0.7525\n",
            "Epoch 20/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9758 - val_loss: 1.4270 - val_sparse_categorical_accuracy: 0.7324\n",
            "Epoch 21/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 75ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9810 - val_loss: 1.2614 - val_sparse_categorical_accuracy: 0.7623\n",
            "Epoch 22/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9823 - val_loss: 1.0657 - val_sparse_categorical_accuracy: 0.7851\n",
            "Epoch 23/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - loss: 0.0566 - sparse_categorical_accuracy: 0.9810 - val_loss: 1.7176 - val_sparse_categorical_accuracy: 0.7162\n",
            "Epoch 24/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 75ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9822 - val_loss: 1.4263 - val_sparse_categorical_accuracy: 0.7485\n",
            "Epoch 25/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 76ms/step - loss: 0.0415 - sparse_categorical_accuracy: 0.9847 - val_loss: 1.4012 - val_sparse_categorical_accuracy: 0.7623\n",
            "Epoch 26/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9829 - val_loss: 1.2475 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 27/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9836 - val_loss: 1.3596 - val_sparse_categorical_accuracy: 0.7655\n",
            "Epoch 28/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9845 - val_loss: 1.2515 - val_sparse_categorical_accuracy: 0.7750\n",
            "Epoch 29/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.0400 - sparse_categorical_accuracy: 0.9865 - val_loss: 1.5078 - val_sparse_categorical_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9879 - val_loss: 1.1362 - val_sparse_categorical_accuracy: 0.7825\n",
            "Epoch 31/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - loss: 0.0400 - sparse_categorical_accuracy: 0.9859 - val_loss: 1.1463 - val_sparse_categorical_accuracy: 0.7894\n",
            "Epoch 32/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9890 - val_loss: 1.2519 - val_sparse_categorical_accuracy: 0.7923\n",
            "Epoch 33/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.9882 - val_loss: 1.3637 - val_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 34/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9880 - val_loss: 1.3481 - val_sparse_categorical_accuracy: 0.7638\n",
            "Epoch 35/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9896 - val_loss: 1.4680 - val_sparse_categorical_accuracy: 0.7652\n",
            "Epoch 36/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 78ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9853 - val_loss: 1.1623 - val_sparse_categorical_accuracy: 0.7980\n",
            "Epoch 37/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 74ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9904 - val_loss: 1.5711 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 38/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 78ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9893 - val_loss: 1.2882 - val_sparse_categorical_accuracy: 0.7740\n",
            "Epoch 39/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 74ms/step - loss: 0.0318 - sparse_categorical_accuracy: 0.9887 - val_loss: 1.2876 - val_sparse_categorical_accuracy: 0.7752\n",
            "Epoch 40/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - loss: 0.0262 - sparse_categorical_accuracy: 0.9912 - val_loss: 1.3289 - val_sparse_categorical_accuracy: 0.7780\n",
            "Epoch 41/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9898 - val_loss: 1.3262 - val_sparse_categorical_accuracy: 0.7848\n",
            "Epoch 42/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9886 - val_loss: 1.3262 - val_sparse_categorical_accuracy: 0.7770\n",
            "Epoch 43/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - loss: 0.0251 - sparse_categorical_accuracy: 0.9915 - val_loss: 1.1441 - val_sparse_categorical_accuracy: 0.7951\n",
            "Epoch 44/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9925 - val_loss: 1.1287 - val_sparse_categorical_accuracy: 0.7999\n",
            "Epoch 45/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 77ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9858 - val_loss: 1.2951 - val_sparse_categorical_accuracy: 0.7866\n",
            "Epoch 46/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 74ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9913 - val_loss: 1.2530 - val_sparse_categorical_accuracy: 0.7961\n",
            "Epoch 47/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9933 - val_loss: 1.1630 - val_sparse_categorical_accuracy: 0.8020\n",
            "Epoch 48/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.0262 - sparse_categorical_accuracy: 0.9908 - val_loss: 1.1932 - val_sparse_categorical_accuracy: 0.7967\n",
            "Epoch 49/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - loss: 0.0276 - sparse_categorical_accuracy: 0.9909 - val_loss: 1.3546 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 50/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9938 - val_loss: 1.6016 - val_sparse_categorical_accuracy: 0.7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0b-StxXiXBxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z1w6l3cWXB1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hQgyqDVxXB36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bO84Eim2XB7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WpHuX6boXB91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3LgMKpaMXCAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3b5-QhrPXCC2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJCHzhkLfskm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}