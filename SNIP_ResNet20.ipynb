{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhartiansh/cnn_pruning_cifar10/blob/main/SNIP_ResNet20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okYcZAa7Y4CB",
        "outputId": "5126dc9e-8b15-4a7d-bce3-a15a7ea64b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cnn_pruning_cifar10'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 212 (delta 36), reused 2 (delta 2), pack-reused 144 (from 1)\u001b[K\n",
            "Receiving objects: 100% (212/212), 130.56 KiB | 1.33 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n",
            "/content/cnn_pruning_cifar10\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bhartiansh/cnn_pruning_cifar10.git\n",
        "%cd cnn_pruning_cifar10\n",
        "\n",
        "!pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from models.resnet20 import build_resnet20\n",
        "\n",
        "def compute_snip_scores(model, x_sample, y_sample):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x_sample, training=True)\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_sample, logits)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    scores = []\n",
        "\n",
        "    for w, g in zip(model.trainable_weights, grads):\n",
        "        if 'kernel' in w.name:\n",
        "            scores.append(tf.reshape(tf.abs(w * g), [-1]))\n",
        "\n",
        "    return tf.concat(scores, axis=0)\n",
        "\n",
        "def apply_snip_mask(model, x_sample, y_sample, sparsity=0.5):\n",
        "    scores = compute_snip_scores(model, x_sample, y_sample)\n",
        "    k = int((1 - sparsity) * scores.shape[0])\n",
        "    threshold = tf.sort(scores)[k]\n",
        "\n",
        "    for w in model.trainable_weights:\n",
        "        if 'kernel' in w.name:\n",
        "            mask = tf.cast(tf.abs(w) >= threshold, tf.float32)\n",
        "            w.assign(w * mask)\n",
        "\n",
        "def quick_train(model, x_train, y_train, x_test, y_test, epochs=10, batch_size=64):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train,\n",
        "              validation_data=(x_test, y_test),\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=2)\n",
        "    return model"
      ],
      "metadata": {
        "id": "s1TyxqvhY4oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PU5ZonT2seWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kYLjhFT-seUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pXCsZF7vseRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GvK_thi2seOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H5cUvg2fseLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mUiHg_E_seIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WfW47b1lseF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "svKwDT_dseC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CAhBLD7isd_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PjGJ7yhhsd9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Run it ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Load CIFAR-10\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "\n",
        "    # Build model\n",
        "    model = build_resnet20()\n",
        "\n",
        "    # Run dummy forward pass to initialize weights\n",
        "    model(tf.convert_to_tensor(x_train[:1]), training=False)\n",
        "\n",
        "    # SNIP pruning using small batch\n",
        "    apply_snip_mask(model, x_train[:64], y_train[:64], sparsity=0.3)\n",
        "\n",
        "    # Very quick fine-tuning\n",
        "    quick_train(model, x_train, y_train, x_test, y_test, epochs=30, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcnnvwgAc3kr",
        "outputId": "91089ae6-a98a-4aae-a47e-3036477a496b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Epoch 1/30\n",
            "782/782 - 61s - loss: 1.3401 - accuracy: 0.5109 - val_loss: 1.1363 - val_accuracy: 0.5894 - 61s/epoch - 78ms/step\n",
            "Epoch 2/30\n",
            "782/782 - 54s - loss: 0.9124 - accuracy: 0.6764 - val_loss: 1.2805 - val_accuracy: 0.5745 - 54s/epoch - 69ms/step\n",
            "Epoch 3/30\n",
            "782/782 - 57s - loss: 0.7387 - accuracy: 0.7416 - val_loss: 1.0174 - val_accuracy: 0.6621 - 57s/epoch - 73ms/step\n",
            "Epoch 4/30\n",
            "782/782 - 57s - loss: 0.6244 - accuracy: 0.7817 - val_loss: 0.7847 - val_accuracy: 0.7267 - 57s/epoch - 74ms/step\n",
            "Epoch 5/30\n",
            "782/782 - 55s - loss: 0.5460 - accuracy: 0.8086 - val_loss: 1.1357 - val_accuracy: 0.6390 - 55s/epoch - 70ms/step\n",
            "Epoch 6/30\n",
            "782/782 - 54s - loss: 0.4848 - accuracy: 0.8329 - val_loss: 0.7083 - val_accuracy: 0.7633 - 54s/epoch - 69ms/step\n",
            "Epoch 7/30\n",
            "782/782 - 54s - loss: 0.4294 - accuracy: 0.8519 - val_loss: 0.7287 - val_accuracy: 0.7584 - 54s/epoch - 69ms/step\n",
            "Epoch 8/30\n",
            "782/782 - 54s - loss: 0.3783 - accuracy: 0.8685 - val_loss: 0.6713 - val_accuracy: 0.7824 - 54s/epoch - 69ms/step\n",
            "Epoch 9/30\n",
            "782/782 - 54s - loss: 0.3414 - accuracy: 0.8796 - val_loss: 0.8639 - val_accuracy: 0.7473 - 54s/epoch - 69ms/step\n",
            "Epoch 10/30\n",
            "782/782 - 54s - loss: 0.2957 - accuracy: 0.8973 - val_loss: 0.7510 - val_accuracy: 0.7699 - 54s/epoch - 69ms/step\n",
            "Epoch 11/30\n",
            "782/782 - 54s - loss: 0.2673 - accuracy: 0.9056 - val_loss: 0.7900 - val_accuracy: 0.7567 - 54s/epoch - 70ms/step\n",
            "Epoch 12/30\n",
            "782/782 - 54s - loss: 0.2333 - accuracy: 0.9183 - val_loss: 0.8941 - val_accuracy: 0.7524 - 54s/epoch - 69ms/step\n",
            "Epoch 13/30\n",
            "782/782 - 54s - loss: 0.2040 - accuracy: 0.9284 - val_loss: 0.8239 - val_accuracy: 0.7787 - 54s/epoch - 70ms/step\n",
            "Epoch 14/30\n",
            "782/782 - 54s - loss: 0.1815 - accuracy: 0.9360 - val_loss: 0.8989 - val_accuracy: 0.7575 - 54s/epoch - 70ms/step\n",
            "Epoch 15/30\n",
            "782/782 - 54s - loss: 0.1650 - accuracy: 0.9413 - val_loss: 0.8558 - val_accuracy: 0.7751 - 54s/epoch - 69ms/step\n",
            "Epoch 16/30\n",
            "782/782 - 54s - loss: 0.1470 - accuracy: 0.9488 - val_loss: 1.3118 - val_accuracy: 0.7042 - 54s/epoch - 69ms/step\n",
            "Epoch 17/30\n",
            "782/782 - 54s - loss: 0.1425 - accuracy: 0.9503 - val_loss: 0.7747 - val_accuracy: 0.7926 - 54s/epoch - 70ms/step\n",
            "Epoch 18/30\n",
            "782/782 - 54s - loss: 0.1190 - accuracy: 0.9576 - val_loss: 0.8334 - val_accuracy: 0.7919 - 54s/epoch - 69ms/step\n",
            "Epoch 19/30\n",
            "782/782 - 54s - loss: 0.1131 - accuracy: 0.9606 - val_loss: 0.9117 - val_accuracy: 0.7767 - 54s/epoch - 69ms/step\n",
            "Epoch 20/30\n",
            "782/782 - 54s - loss: 0.1074 - accuracy: 0.9628 - val_loss: 0.9099 - val_accuracy: 0.7822 - 54s/epoch - 69ms/step\n",
            "Epoch 21/30\n",
            "782/782 - 54s - loss: 0.1013 - accuracy: 0.9639 - val_loss: 0.8923 - val_accuracy: 0.7947 - 54s/epoch - 69ms/step\n",
            "Epoch 22/30\n",
            "782/782 - 54s - loss: 0.0893 - accuracy: 0.9695 - val_loss: 0.9249 - val_accuracy: 0.7800 - 54s/epoch - 69ms/step\n",
            "Epoch 23/30\n",
            "782/782 - 55s - loss: 0.0911 - accuracy: 0.9676 - val_loss: 1.2014 - val_accuracy: 0.7423 - 55s/epoch - 70ms/step\n",
            "Epoch 24/30\n",
            "782/782 - 54s - loss: 0.0860 - accuracy: 0.9692 - val_loss: 1.1128 - val_accuracy: 0.7753 - 54s/epoch - 69ms/step\n",
            "Epoch 25/30\n",
            "782/782 - 54s - loss: 0.0808 - accuracy: 0.9718 - val_loss: 1.0275 - val_accuracy: 0.7793 - 54s/epoch - 69ms/step\n",
            "Epoch 26/30\n",
            "782/782 - 54s - loss: 0.0775 - accuracy: 0.9728 - val_loss: 0.9588 - val_accuracy: 0.7964 - 54s/epoch - 69ms/step\n",
            "Epoch 27/30\n",
            "782/782 - 54s - loss: 0.0725 - accuracy: 0.9752 - val_loss: 0.9976 - val_accuracy: 0.7877 - 54s/epoch - 69ms/step\n",
            "Epoch 28/30\n",
            "782/782 - 55s - loss: 0.0800 - accuracy: 0.9719 - val_loss: 0.9799 - val_accuracy: 0.7906 - 55s/epoch - 70ms/step\n",
            "Epoch 29/30\n",
            "782/782 - 54s - loss: 0.0648 - accuracy: 0.9772 - val_loss: 1.0968 - val_accuracy: 0.7811 - 54s/epoch - 69ms/step\n",
            "Epoch 30/30\n",
            "782/782 - 54s - loss: 0.0622 - accuracy: 0.9783 - val_loss: 1.1624 - val_accuracy: 0.7736 - 54s/epoch - 69ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3plp_uAbsgep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RSyMt8UFsgb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2LEC1APqsgY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QSE_uGmcsgWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YNQgKG1AsgTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jkw0In0RsgQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JtyCxvISsgJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JvHHos8CsgGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Run it ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Load CIFAR-10\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "\n",
        "    # Build model\n",
        "    model = build_resnet20()\n",
        "\n",
        "    # Run dummy forward pass to initialize weights\n",
        "    model(tf.convert_to_tensor(x_train[:1]), training=False)\n",
        "\n",
        "    # SNIP pruning using small batch\n",
        "    apply_snip_mask(model, x_train[:64], y_train[:64], sparsity=0.5)\n",
        "\n",
        "    # Very quick fine-tuning\n",
        "    quick_train(model, x_train, y_train, x_test, y_test, epochs=30, batch_size=64)"
      ],
      "metadata": {
        "id": "Ztn4hVZRY6L_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1e4c98-9a3c-41e2-b4cb-9b74b0eac8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n",
            "Epoch 1/30\n",
            "782/782 - 347s - loss: 1.3104 - accuracy: 0.5265 - val_loss: 1.8690 - val_accuracy: 0.4699 - 347s/epoch - 444ms/step\n",
            "Epoch 2/30\n",
            "782/782 - 342s - loss: 0.8921 - accuracy: 0.6839 - val_loss: 0.9585 - val_accuracy: 0.6720 - 342s/epoch - 437ms/step\n",
            "Epoch 3/30\n",
            "782/782 - 341s - loss: 0.7132 - accuracy: 0.7499 - val_loss: 0.8214 - val_accuracy: 0.7183 - 341s/epoch - 436ms/step\n",
            "Epoch 4/30\n",
            "782/782 - 335s - loss: 0.6087 - accuracy: 0.7879 - val_loss: 0.8776 - val_accuracy: 0.7090 - 335s/epoch - 429ms/step\n",
            "Epoch 5/30\n",
            "782/782 - 337s - loss: 0.5343 - accuracy: 0.8143 - val_loss: 0.7388 - val_accuracy: 0.7482 - 337s/epoch - 431ms/step\n",
            "Epoch 6/30\n",
            "782/782 - 333s - loss: 0.4738 - accuracy: 0.8357 - val_loss: 0.7324 - val_accuracy: 0.7598 - 333s/epoch - 426ms/step\n",
            "Epoch 7/30\n",
            "782/782 - 335s - loss: 0.4178 - accuracy: 0.8543 - val_loss: 0.8825 - val_accuracy: 0.7353 - 335s/epoch - 428ms/step\n",
            "Epoch 8/30\n",
            "782/782 - 334s - loss: 0.3747 - accuracy: 0.8698 - val_loss: 0.8615 - val_accuracy: 0.7338 - 334s/epoch - 427ms/step\n",
            "Epoch 9/30\n",
            "782/782 - 339s - loss: 0.3342 - accuracy: 0.8831 - val_loss: 0.6870 - val_accuracy: 0.7822 - 339s/epoch - 434ms/step\n",
            "Epoch 10/30\n",
            "782/782 - 333s - loss: 0.2939 - accuracy: 0.8983 - val_loss: 0.7412 - val_accuracy: 0.7586 - 333s/epoch - 426ms/step\n",
            "Epoch 11/30\n",
            "782/782 - 339s - loss: 0.2556 - accuracy: 0.9099 - val_loss: 0.6835 - val_accuracy: 0.7865 - 339s/epoch - 433ms/step\n",
            "Epoch 12/30\n",
            "782/782 - 336s - loss: 0.2288 - accuracy: 0.9198 - val_loss: 0.7476 - val_accuracy: 0.7832 - 336s/epoch - 429ms/step\n",
            "Epoch 13/30\n",
            "782/782 - 337s - loss: 0.1980 - accuracy: 0.9304 - val_loss: 0.6978 - val_accuracy: 0.7921 - 337s/epoch - 431ms/step\n",
            "Epoch 14/30\n",
            "782/782 - 341s - loss: 0.1791 - accuracy: 0.9367 - val_loss: 0.8147 - val_accuracy: 0.7791 - 341s/epoch - 437ms/step\n",
            "Epoch 15/30\n",
            "782/782 - 343s - loss: 0.1631 - accuracy: 0.9438 - val_loss: 1.0092 - val_accuracy: 0.7348 - 343s/epoch - 438ms/step\n",
            "Epoch 16/30\n",
            "782/782 - 341s - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.7751 - val_accuracy: 0.7934 - 341s/epoch - 436ms/step\n",
            "Epoch 17/30\n",
            "782/782 - 336s - loss: 0.1342 - accuracy: 0.9526 - val_loss: 1.0339 - val_accuracy: 0.7665 - 336s/epoch - 430ms/step\n",
            "Epoch 18/30\n",
            "782/782 - 335s - loss: 0.1174 - accuracy: 0.9587 - val_loss: 0.8586 - val_accuracy: 0.7793 - 335s/epoch - 429ms/step\n",
            "Epoch 19/30\n",
            "782/782 - 340s - loss: 0.1097 - accuracy: 0.9616 - val_loss: 0.9235 - val_accuracy: 0.7836 - 340s/epoch - 434ms/step\n",
            "Epoch 20/30\n",
            "782/782 - 334s - loss: 0.1028 - accuracy: 0.9647 - val_loss: 1.3267 - val_accuracy: 0.7363 - 334s/epoch - 427ms/step\n",
            "Epoch 21/30\n",
            "782/782 - 334s - loss: 0.0980 - accuracy: 0.9655 - val_loss: 0.9804 - val_accuracy: 0.7849 - 334s/epoch - 427ms/step\n",
            "Epoch 22/30\n",
            "782/782 - 339s - loss: 0.0910 - accuracy: 0.9674 - val_loss: 1.1012 - val_accuracy: 0.7610 - 339s/epoch - 434ms/step\n",
            "Epoch 23/30\n",
            "782/782 - 335s - loss: 0.0842 - accuracy: 0.9709 - val_loss: 0.9715 - val_accuracy: 0.7950 - 335s/epoch - 429ms/step\n",
            "Epoch 24/30\n",
            "782/782 - 343s - loss: 0.0817 - accuracy: 0.9708 - val_loss: 1.3155 - val_accuracy: 0.7462 - 343s/epoch - 438ms/step\n",
            "Epoch 25/30\n",
            "782/782 - 336s - loss: 0.0815 - accuracy: 0.9712 - val_loss: 0.9931 - val_accuracy: 0.7925 - 336s/epoch - 430ms/step\n",
            "Epoch 26/30\n",
            "782/782 - 344s - loss: 0.0720 - accuracy: 0.9743 - val_loss: 1.0446 - val_accuracy: 0.7800 - 344s/epoch - 440ms/step\n",
            "Epoch 27/30\n",
            "782/782 - 337s - loss: 0.0684 - accuracy: 0.9760 - val_loss: 1.0689 - val_accuracy: 0.7824 - 337s/epoch - 431ms/step\n",
            "Epoch 28/30\n",
            "782/782 - 343s - loss: 0.0737 - accuracy: 0.9745 - val_loss: 1.1591 - val_accuracy: 0.7696 - 343s/epoch - 439ms/step\n",
            "Epoch 29/30\n",
            "782/782 - 337s - loss: 0.0629 - accuracy: 0.9784 - val_loss: 0.9875 - val_accuracy: 0.7970 - 337s/epoch - 431ms/step\n",
            "Epoch 30/30\n",
            "782/782 - 344s - loss: 0.0677 - accuracy: 0.9764 - val_loss: 1.0050 - val_accuracy: 0.7921 - 344s/epoch - 440ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3p9CdkG8siN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FL11mhLnsiLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TWjemNMBsiIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MbFz2_6psiGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7JLXtMfmsiDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-CoDk2oIsiA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tzVILwAXsheR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Run it ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Load CIFAR-10\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "\n",
        "    # Build model\n",
        "    model = build_resnet20()\n",
        "\n",
        "    # Run dummy forward pass to initialize weights\n",
        "    model(tf.convert_to_tensor(x_train[:1]), training=False)\n",
        "\n",
        "    # SNIP pruning using small batch\n",
        "    apply_snip_mask(model, x_train[:64], y_train[:64], sparsity=0.7)\n",
        "\n",
        "    # Very quick fine-tuning\n",
        "    quick_train(model, x_train, y_train, x_test, y_test, epochs=30, batch_size=64)"
      ],
      "metadata": {
        "id": "ZNnMA1lIY6a-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4880f9-858d-4ff4-cff1-d873b6d21bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 - 344s - loss: 1.3406 - accuracy: 0.5134 - val_loss: 1.9493 - val_accuracy: 0.4587 - 344s/epoch - 440ms/step\n",
            "Epoch 2/30\n",
            "782/782 - 339s - loss: 0.9146 - accuracy: 0.6769 - val_loss: 1.2685 - val_accuracy: 0.5858 - 339s/epoch - 433ms/step\n",
            "Epoch 3/30\n",
            "782/782 - 335s - loss: 0.7333 - accuracy: 0.7429 - val_loss: 1.1805 - val_accuracy: 0.6415 - 335s/epoch - 429ms/step\n",
            "Epoch 4/30\n",
            "782/782 - 335s - loss: 0.6250 - accuracy: 0.7823 - val_loss: 0.8109 - val_accuracy: 0.7253 - 335s/epoch - 429ms/step\n",
            "Epoch 5/30\n",
            "782/782 - 337s - loss: 0.5442 - accuracy: 0.8109 - val_loss: 0.7143 - val_accuracy: 0.7580 - 337s/epoch - 430ms/step\n",
            "Epoch 6/30\n",
            "782/782 - 337s - loss: 0.4838 - accuracy: 0.8318 - val_loss: 0.9642 - val_accuracy: 0.7066 - 337s/epoch - 430ms/step\n",
            "Epoch 7/30\n",
            "782/782 - 335s - loss: 0.4270 - accuracy: 0.8509 - val_loss: 0.7065 - val_accuracy: 0.7658 - 335s/epoch - 428ms/step\n",
            "Epoch 8/30\n",
            "782/782 - 341s - loss: 0.3816 - accuracy: 0.8663 - val_loss: 0.7525 - val_accuracy: 0.7628 - 341s/epoch - 436ms/step\n",
            "Epoch 9/30\n",
            "782/782 - 336s - loss: 0.3381 - accuracy: 0.8808 - val_loss: 0.6845 - val_accuracy: 0.7782 - 336s/epoch - 429ms/step\n",
            "Epoch 10/30\n",
            "782/782 - 335s - loss: 0.2997 - accuracy: 0.8946 - val_loss: 0.9718 - val_accuracy: 0.7294 - 335s/epoch - 429ms/step\n",
            "Epoch 11/30\n",
            "782/782 - 342s - loss: 0.2662 - accuracy: 0.9072 - val_loss: 0.7862 - val_accuracy: 0.7691 - 342s/epoch - 438ms/step\n",
            "Epoch 12/30\n",
            "782/782 - 342s - loss: 0.2328 - accuracy: 0.9183 - val_loss: 0.7535 - val_accuracy: 0.7769 - 342s/epoch - 437ms/step\n",
            "Epoch 13/30\n",
            "782/782 - 334s - loss: 0.2077 - accuracy: 0.9265 - val_loss: 0.8669 - val_accuracy: 0.7665 - 334s/epoch - 428ms/step\n",
            "Epoch 14/30\n",
            "782/782 - 335s - loss: 0.1851 - accuracy: 0.9347 - val_loss: 0.6720 - val_accuracy: 0.8032 - 335s/epoch - 428ms/step\n",
            "Epoch 15/30\n",
            "782/782 - 334s - loss: 0.1592 - accuracy: 0.9432 - val_loss: 0.7132 - val_accuracy: 0.8024 - 334s/epoch - 428ms/step\n",
            "Epoch 16/30\n",
            "782/782 - 336s - loss: 0.1462 - accuracy: 0.9486 - val_loss: 1.0575 - val_accuracy: 0.7433 - 336s/epoch - 430ms/step\n",
            "Epoch 17/30\n",
            "782/782 - 336s - loss: 0.1391 - accuracy: 0.9494 - val_loss: 0.9071 - val_accuracy: 0.7737 - 336s/epoch - 430ms/step\n",
            "Epoch 18/30\n",
            "782/782 - 335s - loss: 0.1232 - accuracy: 0.9566 - val_loss: 0.8168 - val_accuracy: 0.7969 - 335s/epoch - 429ms/step\n",
            "Epoch 19/30\n",
            "782/782 - 342s - loss: 0.1105 - accuracy: 0.9609 - val_loss: 0.9198 - val_accuracy: 0.7767 - 342s/epoch - 437ms/step\n",
            "Epoch 20/30\n",
            "782/782 - 342s - loss: 0.1078 - accuracy: 0.9619 - val_loss: 0.9797 - val_accuracy: 0.7655 - 342s/epoch - 437ms/step\n",
            "Epoch 21/30\n",
            "782/782 - 337s - loss: 0.1049 - accuracy: 0.9623 - val_loss: 0.8586 - val_accuracy: 0.7939 - 337s/epoch - 431ms/step\n",
            "Epoch 22/30\n",
            "782/782 - 336s - loss: 0.0875 - accuracy: 0.9694 - val_loss: 0.8312 - val_accuracy: 0.7943 - 336s/epoch - 430ms/step\n",
            "Epoch 23/30\n",
            "782/782 - 334s - loss: 0.0903 - accuracy: 0.9679 - val_loss: 1.0211 - val_accuracy: 0.7773 - 334s/epoch - 427ms/step\n",
            "Epoch 24/30\n",
            "782/782 - 337s - loss: 0.0827 - accuracy: 0.9716 - val_loss: 0.9807 - val_accuracy: 0.7855 - 337s/epoch - 430ms/step\n",
            "Epoch 25/30\n",
            "782/782 - 337s - loss: 0.0811 - accuracy: 0.9709 - val_loss: 1.2370 - val_accuracy: 0.7610 - 337s/epoch - 431ms/step\n",
            "Epoch 26/30\n",
            "782/782 - 337s - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.9981 - val_accuracy: 0.8004 - 337s/epoch - 431ms/step\n",
            "Epoch 27/30\n",
            "782/782 - 341s - loss: 0.0728 - accuracy: 0.9746 - val_loss: 0.9432 - val_accuracy: 0.7982 - 341s/epoch - 436ms/step\n",
            "Epoch 28/30\n",
            "782/782 - 335s - loss: 0.0772 - accuracy: 0.9730 - val_loss: 1.0251 - val_accuracy: 0.7856 - 335s/epoch - 429ms/step\n",
            "Epoch 29/30\n",
            "782/782 - 341s - loss: 0.0591 - accuracy: 0.9789 - val_loss: 1.0750 - val_accuracy: 0.7858 - 341s/epoch - 437ms/step\n",
            "Epoch 30/30\n",
            "782/782 - 337s - loss: 0.0735 - accuracy: 0.9742 - val_loss: 1.1716 - val_accuracy: 0.7699 - 337s/epoch - 430ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lwBu6ts_Y6p7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T__0LkBqY6s9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BhVE1fs2Y6wF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U8zw6Lz6Y6zN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GkgQHAhXY62N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rTmYEj7qY65P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yuXi8rLSY68J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GmajiGKXY6_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U85y_972Y7CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Force compatible versions (reset everything to Colab defaults)\n",
        "!pip install -U --force-reinstall numpy==1.23.5\n",
        "!pip install -U --force-reinstall tensorflow==2.14.0\n",
        "!pip install -U tensorflow-model-optimization\n",
        "\n",
        "# 2. Restart runtime automatically after install\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CFNb5bqNY7Me",
        "outputId": "c7242589-8671-49f4-923d-2c09b6ab4afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "871e4de7b12f40719ed56eee63ca5e54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.14.0)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.14.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow==2.14.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.14.0)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.14.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow==2.14.0)\n",
            "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.14.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy>=1.23.5 (from tensorflow==2.14.0)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow==2.14.0)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.14.0)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.14.0)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow==2.14.0)\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow==2.14.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.14.0)\n",
            "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.14.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.14.0)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.14.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.1\n",
            "    Uninstalling typing_extensions-4.13.1:\n",
            "      Successfully uninstalled typing_extensions-4.13.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-auth-2.39.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-2.14.0 libclang-18.1.1 markdown-3.8 ml-dtypes-0.2.0 numpy-2.2.4 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-24.2 protobuf-4.25.6 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-78.1.0 six-1.17.0 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "six"
                ]
              },
              "id": "b85a0c1924b742e8b72c980bef8f5cd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting absl-py~=1.2 (from tensorflow-model-optimization)\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Collecting numpy~=1.23 (from tensorflow-model-optimization)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.14.1)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, absl-py, tensorflow-model-optimization\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-1.4.0 numpy-1.26.4 tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DcuPL7HrY-vL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}